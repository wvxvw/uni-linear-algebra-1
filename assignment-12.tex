% Created 2014-11-21 Fri 23:31
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{hyperref}
\tolerance=1000
\usepackage[utf8]{inputenc}
\usepackage[usenames,dvipsnames]{color}
\usepackage{a4wide}
\usepackage[backend=bibtex, style=numeric]{biblatex}
\usepackage{commath}
\usepackage{tikz}
\usepackage{amsmath}
\usetikzlibrary{shapes,backgrounds}
\usepackage{marginnote}
\usepackage{enumerate}
\usepackage{listings}
\usepackage{color}
\hypersetup{urlcolor=blue}
\hypersetup{colorlinks,urlcolor=blue}
\addbibresource{bibliography.bib}
\setlength{\parskip}{16pt plus 2pt minus 2pt}
\definecolor{codebg}{rgb}{0.96,0.99,0.8}
\author{Oleg Sivokon}
\date{\textit{<2014-11-15 Sat>}}
\title{Assignment 12, Linear Algebra 1}
\hypersetup{
  pdfkeywords={Assignment, Linear Algebra},
  pdfsubject={First asssignment in the course Linear Algebra 1},
  pdfcreator={Emacs 25.0.50.1 (Org mode 8.2.2)}}
\begin{document}

\maketitle
\tableofcontents


\definecolor{codebg}{rgb}{0.96,0.99,0.8}
\lstnewenvironment{maxima}{%
  \lstset{backgroundcolor=\color{codebg},
    frame=single,
    framerule=0pt,
    basicstyle=\ttfamily\scriptsize,
    columns=fixed}}{}
}
\makeatletter
\newcommand{\verbatimfont}[1]{\renewcommand{\verbatim@font}{\ttfamily#1}}
\makeatother
\verbatimfont{\small}%
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

 \clearpage

\section{Problems}
\label{sec-1}

\subsection{Problem 1}
\label{sec-1-1}

Given two systems of linear equations $O$ homogenous and $M$ nonhomogenous.

\begin{equation*}
  \left.
    \begin{alignedat}{4}
      & ax + & by + & cz = & 0 \\
      & fx + & gy + & hz = & 0 \\
    \end{alignedat}
    \quad \right\}
  \begin{aligned} = O \end{aligned}
  \left.
    \begin{alignedat}{4}
      & ax + & by + & cz = & d \\
      & fx + & gy + & hz = & k \\
    \end{alignedat}
    \quad \right\}
  \begin{aligned} = M \end{aligned}
\end{equation*}


$(1, 0, 1)$ and $(-1, 1, 1)$ are known to be the solutions of $O$ and $(2, -3, 1)$
is a solution of $M$.

Find general solution for $O$.

\subsubsection{Answer 1}
\label{sec-1-1-1}
\subsection{Problem 2}
\label{sec-1-2}

Given matrices

\begin{equation*}
  \begin{bmatrix}
    1 & 0 & 1  & 0 \\
    0 & 1 & 0  & 1 \\
    0 & 0 & 1  & -1 \\
  \end{bmatrix}
  \begin{aligned} = B \end{aligned}
  \begin{bmatrix}
    1 & 0 & 1  & 0 \\
    2 & 1 & 2  & 1 \\
    0 & 0 & 3  & -3 \\
  \end{bmatrix}
  \begin{aligned} = A \end{aligned}
\end{equation*}

\begin{enumerate}
\item Use elementary operations to obtain $C$ such that $CC^{-1}=I$ and $B = CA$.
\item Write $C$ as a product of elementary matrices.
\end{enumerate}

\subsubsection{Answer 2}
\label{sec-1-2-1}
It is easier to start answering from (2). Since we can see that all we need
is to find two elementary matrices, one such that it would reduce the second
row by twice the first row and one that would diminish the third row by
${1\over 3}$, we can readily represent these operations as multiplication
of two elementary matrices:

\begin{equation*}
  \begin{bmatrix}
    1 & 0 & 0 \\
    -2 & 1 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}
  \begin{aligned} = C_1 \end{aligned}
  \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & {1\over 3} \\
  \end{bmatrix}
  \begin{aligned} = C_2 \end{aligned}
\end{equation*}

The product of $C_1 \times C_2 = C$ gives us the matrix $C$ we were asked to
find.

\begin{equation*}
  \begin{bmatrix}
    1 & 0 & 0 \\
    -2 & 1 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}
  \begin{aligned} \times \end{aligned}
  \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & {1\over 3} \\
  \end{bmatrix}
  \begin{aligned} = \end{aligned}
  \begin{bmatrix}
    1 & 0 & 0 \\
    -2 & 1 & 0 \\
    0 & 0 & {1\over 3} \\
  \end{bmatrix}
\end{equation*}

Now, let's find $C^{-1}$:

\begin{equation*}
  \begin{bmatrix}[ccc|ccc]
    1  & 0 & 0          & 1 & 0 & 0 \\
    -2 & 1 & 0          & 0 & 1 & 0 \\
    0  & 0 & {1\over 3} & 0 & 0 & 1 \\
  \end{bmatrix}
  \begin{aligned} \xrightarrow{R_2 = R_2 + 2R_1} \end{aligned}
  \begin{bmatrix}[ccc|ccc]
    1 & 0 & 0          & 1 & 0 & 0 \\
    0 & 1 & 0          & 2 & 1 & 0 \\
    0 & 0 & {1\over 3} & 0 & 0 & 1 \\
  \end{bmatrix}
  \begin{aligned} \xrightarrow{R_3 = 3R_3} \end{aligned}
  \begin{bmatrix}[ccc|ccc]
    1 & 0 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 2 & 1 & 0 \\
    0 & 0 & 1 & 0 & 0 & 3 \\
  \end{bmatrix}
\end{equation*}

Finally $CC^{-1}=I$:

\begin{equation*}
  \begin{bmatrix}
    1 & 0 & 0 \\
    -2 & 1 & 0 \\
    0 & 0 & {1\over 3} \\
  \end{bmatrix}
  \begin{aligned} \times \end{aligned}
  \begin{bmatrix}
    1 & 0 & 0 \\
    2 & 1 & 0 \\
    0 & 0 & 3 \\
  \end{bmatrix}
  \begin{aligned} = \end{aligned}
  \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}
\end{equation*}

\subsection{Problem 3}
\label{sec-1-3}

Let $A$ be a square matrix of the $n$-th order.  Assume $A^2+A+I=0$ holds.

\begin{enumerate}
\item Prove that $A$ is invertible and that $A^2=A^{-1}$.
\item Prove $A^2-A+I=0$ is invertible.
\end{enumerate}

Let $A$ and $B$ be of the order of $n \times n$. Prove that if $AB^2-A$ is
invertible, so is $AB-A$.

\subsubsection{Answer 3}
\label{sec-1-3-1}

First, show that $A$ is invertible:

\begin{align*}
  A^2+A+I    =  0  & \iff     & \textrm{given} \\
  AA+A       =  -I & \iff     & \textrm{by simple algebra} \\
  A(A+I)     =  -I & \iff     & \textrm{by associativity} \\
  A(-(A+I))  =  I  & \implies & \textrm{multiplication by scalar} \\
                   &          & \textrm{$A$ is invertible}
\end{align*}

Then, suppose $A^2$ is the inverse of $A$, it must be then:

\begin{align*}
  A^{-1} + A + I = 0   & \iff     & \textrm{by assumption $A^2=A^{-1}$} \\
  A^{-1} + A = -I      & \iff     & \textrm{move $I$ to the right} \\
  AA^{-1} + AA = A(-I) & \iff     & \textrm{multiply both sides by $A$} \\
  I + A^2 = -A         & \iff     & \textrm{simplifying} \\
  I + A^2 + A = 0      & \iff     & \textrm{move $-A$ to the left} \\
  A^2 + A + I = 0      &          & \textrm{completes the proof}
\end{align*}
\subsubsection{Answer 4}
\label{sec-1-3-2}
Now, we show that $A^2-A+I$ is invertible. First, observe that
$A=(A^{-1})^2$ (since we already proven $A^2=A^{-1}$, for complete proof,
see below).  Next, we'll use the $A^2+A+I=0$ to write the following
equation: $A^2-A+I=-2A$.  This reduces the proof to proving that $A$ is
invertible, but it is because $A^2$ is, for extended proof see below.

\begin{align*}
  A^2B  = I & \iff & \textrm{by definition of invertibility} \\
  (AA)B = I & \iff & \textrm{by elementary algebra} \\
  A(AB) = I & \iff & \textrm{by associativity} \\
            &      & \textrm{$A$ is invertible} \\
\end{align*}

\begin{align*}
  A^2  = A^{-1}                & \iff & \textrm{proven earlier} \\
  (AA)^{-1} = A^{-1}A^{-1}     & \iff & \textrm{by definition of invertibility} \\
  (A^{-1})^{-1} = A^{-1}A^{-1} & \iff & \textrm{since $AA = A^2 = A^{-1}$} \\
  A = A^{-1}A^{-1}             &      & \textrm{inverse of inverse} \\
\end{align*}
\subsubsection{Answer 5}
\label{sec-1-3-3}
We can represent the matrix we know to be invertible as a product of
subtraction and addition (by distributivity of multiplication over addition).
We are also guaranteed to have a $C$ s.t. $A^2C-A=I$, thus:

\begin{align*}
  (AB^2 - A)C = I & \iff & \textrm{by definition of invertibility} \\
  A(B^2 - I)C = I & \iff & \textrm{by distributivity of multiplication} \\
  A(B - I)(B + I)C = I & \iff & \textrm{difference of squares $II=I$} \\
  A(B - I) & \implies & \textrm{$(B - I)$ and $A$ are invertible} \\
  (B - I)A & \implies & \textrm{is invertible (product of invertible matrices)} \\
  BA - A & \implies & \textrm{is invertible} \\
\end{align*}
\subsection{Problem 4}
\label{sec-1-4}
Given $p(x)=a_kx^k+a_{k-1}x^{k-1}+...+a_1x+a_0$ is a polynomial and $A$ is
an $n\times n$ matrix. We will denote $p(A)$ the matrix
$p(A)=a_kA^k+a_{k-1}A^{k-1}+...+a_1A+I_n$. Given $p(A)=0$ and $p(0)\neq 0$.

\begin{enumerate}
\item Prove that $A$ is invertible.
\item Prove that $g(A^{-1})=0$ when $g(x)=a_0x^k+a_1x^{k-1}+...+a_{k-1}x+a_k$.
\end{enumerate}

\subsubsection{Answer 6}
\label{sec-1-4-1}
$p(0)\neq 0$ means that the last polynomial term isn't zero (which is even
more obvious if we look at $p(A)$, where the last term is the identity matrix
of the same shape as $A$.  Once we know that the sum of polynomial terms,
with the last term omitted amounts to the additive inverse of identity matrix,
i.e. the $-I$, we obtain that the sum of other polynomial terms must produce
$-I$, which is itself ivertible.

Next, we can employ the distributivity of multiplication over addition and
rewrite the equation as:

\begin{equation*}
  (a_kA^{k-1}+a_{k-1}A^{k-2}+...+a_1)A=-I_n
\end{equation*}

Since $A$ is a factor that gives, multiplied by some other matrix an identity
matrix, it is invertible (by definition of invertibility $BA=I$).
\subsubsection{Answer 7}
\label{sec-1-4-2}
Define $A^{-1}$ to be $-(a_kA^{k-1}+a_{k-1}A^{k-2}+...+a_1)^{-1}$.  (This
immediately follows from \ref{sec-1-4-1}.)  Then observe that $g(x) - a_1$ multiplied
with this term gives us $-I$.  Since we already established $a_1=I$, we
obtain $-I+I=0$, hence $g(A^{-1})=0$.
\subsection{Problem 5}
\label{sec-1-5}
Calculate these determinants:

\begin{equation*}
  D_1 = \left|
    \begin{array}{cccccc}
      a      & b      & 0      & \hdots & \hdots & 0 \\
      0      & a      & b      & 0      & \hdots & 0 \\
      0      & \ddots & \ddots & \ddots &        & \vdots \\
      \vdots &        & \ddots & \ddots & \ddots & 0 \\
      0      & 0      & \hdots & 0      & a      & b \\
      b      & 0      & 0      & \hdots & 0      & a \\
    \end{array}
  \right|
\end{equation*}

\begin{equation*}
  D_2 = \left|
    \begin{array}{ccccccc}
      1      & 2   & 3 & \hdots & n-2 & n-1 & n \\
      2      & 3   & 4 & \hdots & n-1 & n   & n \\
      3      & 4   & 5 & \hdots & n   & n   & n \\
      \vdots &     &   &        &     &     & \vdots \\
      n-2    & n-1 & n & \hdots & n   & n   & n \\
      n-1    & n   & n & \hdots & n   & n   & n \\
      n      & n   & n & \hdots & n   & n   & n \\
    \end{array}
  \right|
\end{equation*}

\subsubsection{Answer 8}
\label{sec-1-5-1}
$D_1$ is the sum of two determinants, one of the identity matrix mutiplied
by $a$, and the other is the full permutation matrix, multiplied by $b$,
which has the same determinant as the identity matrix.  Hence $D_1=a^n+b^n$.
\subsubsection{Answer 9}
\label{sec-1-5-2}
$D_2$ is zero for $n>2$ since those matrices are singular.  In order to get
convinced they are singular, notice that when reducing such matrice to the
row echelon form, the third row will always be the linear combination of the
first and the second rows.  By subtracting a multiple of the first row from
the second, we obtain its two's-complement (i.e. the values of $R_2$, which
I'll denote $r_{2,i}$) will be calculated as $r_{2,i}=-(r_{1,i}-1)$.
The third row then will be $r_{3,i}=3r_{1,i}+2r_{2,i}$.  Direct calculation
of determinants for $n=2$ gives us, using formula $D(A_{2\times 2})=ad-bc$,
$1\times 3-2\times 2=-1$.
% Emacs 25.0.50.1 (Org mode 8.2.2)
\end{document}